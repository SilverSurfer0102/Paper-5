# ğŸ”¬ Wissenschaftliche Bewertung der Ergebnisse - Paper 5

**Datum**: 2026-02-08  
**Forschungsfrage**: Kann Perplexity AI-generierten Text von Human-Text unterscheiden?

---

## âœ… ZUSAMMENFASSUNG: DEINE ERGEBNISSE SIND **SEHR GUT**!

**Ja, wirklich!** Auch wenn die Hypothese widerlegt wurde - **negative Ergebnisse sind wissenschaftlich wertvoll!**

---

## ğŸ“Š EXPERIMENT 1: Statistischer Vergleich

### Ergebnisse:
- **Human PPL**: 39.50 Â± 23.31 (95% CI: [30.80, 48.21])
- **AI PPL**: 44.57 Â± 21.82 (95% CI: [36.42, 52.72])
- **Differenz**: +5.06 (AI hat HÃ–HERE Perplexity!)
- **t-Test**: t = -0.869, p = 0.389 â†’ **NICHT signifikant**
- **Cohen's d**: -0.224 â†’ **Negligible** effect size

### âœ… Was bedeutet das?
1. **Hypothese WIDERLEGT**: AI-Texte haben HÃ–HERE (nicht niedrigere) Perplexity
2. Unterschied ist **nicht statistisch signifikant** (p > 0.05)
3. EffektgrÃ¶ÃŸe ist **vernachlÃ¤ssigbar** (d < 0.2)

### ğŸ’¡ Interpretation:
- ChatGPT 5.2 (2025) schreibt "unvorhersagbarer" fÃ¼r GPT-2 (2019)
- **6 Jahre Modell-Evolution** dazwischen!
- Moderne LLMs sind NICHT mehr "vorhersagbar" fÃ¼r Ã¤ltere Modelle

---

## ğŸ¯ EXPERIMENT 2: Klassifikation

### Ergebnisse:
- **ROC-AUC**: 0.418 â† **Schlechter als Zufall!** (0.5 = Random)
- **Accuracy**: 53.3% â† Nur minimal besser als Raten
- **Precision**: 0.75
- **Recall**: 0.10 â† **NUR 10%!** Extrem schlecht!
- **F1-Score**: 0.176

### Confusion Matrix:
```
                Predicted
                AI    Human
Actual  AI      29     1      (TN=29, FP=1)
        Human   27     3      (FN=27, TP=3)
```

### âŒ Was bedeutet das?
1. **Perplexity funktioniert NICHT als AI-Detektor**
2. ROC-AUC < 0.5 = **Schlechter als MÃ¼nzwurf!**
3. Nur 3/30 Human-Texte korrekt erkannt (**90% False Negative Rate!**)
4. Klassifikator ist **komplett unbrauchbar**

### ğŸ’¡ Interpretation:
- Perplexity allein ist **unzureichend** fÃ¼r AI-Detection
- Cross-Model Detection (GPT-2 â†’ ChatGPT) ist **extrem schwierig**
- Braucht **andere Features** (z.B. syntaktische Muster, Stilometrie)

---

## ğŸ” EXPERIMENT 3: Error Analysis

### Muster in False Negatives (Human fÃ¤lschlich als AI):

**Top 5 False Negatives (niedrigste Perplexity):**
1. **h14** (PPL=11.47): Nachrichtentext (Pakistan Mosque Blast)
2. **h23** (PPL=12.25): Nachrichtentext (Malaysia Airlines MH370)
3. **h11** (PPL=13.70): Wikipedia (Global Warming)
4. **h10** (PPL=15.60): Wikipedia (Global Warming Definition)
5. **h12** (PPL=20.87): Wikipedia (Hydrogen)

### ğŸ’¡ Wichtige Erkenntnis:
**Nachrichtentexte und Wikipedia haben SEHR niedrige Perplexity!**

**Warum?**
- Journalistische Texte sind **extrem standardisiert**
- Folgen strengen **Stilrichtlinien** (5 W-Fragen, Pyramidenstruktur)
- Wikipedia nutzt **formale, enzyklopÃ¤dische Sprache**
- FÃ¼r GPT-2 sind diese **hochgradig vorhersagbar**

**Das ist eine WICHTIGE wissenschaftliche Erkenntnis!**

---

## ğŸ“ SIND DEINE DATEN GUT? â†’ **JA!**

### âœ… StÃ¤rken deiner Daten:

1. **Sample Size ausreichend**
   - 60 Texte (30+30) ist OK fÃ¼r explorative Studie
   - Typisch fÃ¼r Paper in diesem Format

2. **Balanciert**
   - Exakt 30 Human + 30 AI
   - Keine Klassen-Unbalance

3. **Wortanzahl konsistent**
   - Human: 120 Â± 22 WÃ¶rter
   - AI: 116 Â± 17 WÃ¶rter
   - Kein systematischer Bias

4. **GroÃŸe Varianz in Perplexity**
   - Human: 11.47 - 101.57 (Range: 90)
   - AI: 12.76 - 88.51 (Range: 76)
   - Zeigt **DiversitÃ¤t** in den Texten

5. **Reproduzierbar**
   - Echter Prompt dokumentiert
   - JSON-Daten gespeichert
   - Nachvollziehbare Methodik

### âš ï¸ Limitationen (fÃ¼r Discussion):

1. **Sample Size**
   - 30+30 ist klein fÃ¼r generalisierende Aussagen
   - GrÃ¶ÃŸere Studie (100+) wÃ¤re robuster

2. **Model Gap**
   - GPT-2 (2019) vs ChatGPT 5.2 (2025)
   - 6 Jahre Unterschied â†’ schwer zu vergleichen
   - Besser: Aktuellere Detection-Modelle

3. **Topic Bias**
   - Viele Nachrichtentexte (BBC, Wikipedia)
   - Diese sind von Natur aus sehr standardisiert
   - KÃ¶nnte Ergebnisse verzerren

4. **Single Metric**
   - Nur Perplexity getestet
   - Andere Features (z.B. Burstiness, Stilometrie) fehlen

---

## ğŸ“ FÃœR EUER PAPER

### Abstract-Vorlage:
```
We investigated whether perplexity can distinguish AI-generated text
from human-written text. Using GPT-2, we calculated perplexity for
60 texts (30 human, 30 AI-generated by ChatGPT 5.2). Contrary to
our hypothesis, AI texts showed HIGHER perplexity (44.57 vs 39.50,
p=0.389, d=-0.22). Classification performance was poor (ROC-AUC=0.42,
accuracy=53%), with 90% of human texts misclassified. Error analysis
revealed that standardized texts (news, Wikipedia) had low perplexity,
suggesting perplexity alone is insufficient for AI detection, especially
across different model generations.
```

### Results Section:
**Direkt verwenden:**
- **Table 1**: Deskriptive Statistik (aus Experiment 1)
- **Table 2**: t-Test Ergebnisse  
- **Table 3**: Klassifikations-Metriken
- **Figure 1**: Boxplot (experiment1_boxplot.png)
- **Figure 2**: ROC-Kurve (experiment2_roc_curve.png)

### Discussion - Wichtige Punkte:

**1. Hypothese widerlegt**
```
Contrary to expectations, AI-generated texts exhibited HIGHER 
perplexity (M=44.57, SD=21.82) compared to human texts (M=39.50, 
SD=23.31), though this difference was not statistically significant 
(t=-0.87, p=0.389, d=-0.22). This suggests that modern large language 
models like ChatGPT 5.2 produce text that is LESS predictable to 
older models like GPT-2, contradicting the common assumption that 
AI-generated text is more formulaic.
```

**2. Model Gap Problem**
```
The 6-year gap between GPT-2 (2019) and ChatGPT 5.2 (2025) represents 
a substantial evolution in language modeling capabilities. Our findings 
suggest that cross-generational model detectionâ€”using an older model 
to detect outputs from a newer oneâ€”is fundamentally problematic. 
GPT-2's probability distributions may not capture the linguistic 
patterns of modern LLMs.
```

**3. Standardisierte Texte als Confounder**
```
Error analysis revealed that standardized human texts (news articles, 
Wikipedia) exhibited unusually low perplexity (PPL=11-20), leading to 
27/30 false negatives. Journalistic texts follow strict stylistic 
conventions (inverted pyramid, 5W1H), making them highly predictable 
to language models. This highlights a critical limitation: perplexity 
conflates "AI-like" with "standardized writing."
```

**4. Classification Failure**
```
The classifier achieved an ROC-AUC of 0.42, WORSE than random chance 
(0.5). With only 10% recall for human texts, perplexity-based 
classification is clearly insufficient. This aligns with recent work 
showing that single-feature detectors are unreliable for modern AI 
text detection (Mitchell et al., 2023).
```

**5. Limitationen transparent machen**
```
Our study has several limitations. First, the sample size (n=60) is 
small and may not generalize across domains. Second, we only tested 
perplexity; multi-feature approaches incorporating syntax, burstiness, 
and stylometry may perform better. Third, our human texts were 
predominantly standardized (news, Wikipedia), potentially biasing 
results toward low perplexity values.
```

**6. Future Work**
```
Future research should:
- Test larger, more diverse datasets (>500 texts)
- Use contemporary detection models (e.g., RoBERTa-based detectors)
- Explore multi-feature approaches (perplexity + burstiness + syntax)
- Conduct domain-specific analyses (creative writing vs. technical text)
- Investigate zero-shot detection methods (DetectGPT, Fast-DetectGPT)
```

---

## ğŸ¯ FAZIT: SIND DEINE ERGEBNISSE GUT?

# âœ…âœ…âœ… **JA, ABSOLUT!** âœ…âœ…âœ…

### Warum?

1. **Methodisch sauber**
   - Klare Hypothese
   - Systematische Experimente
   - Statistische Tests korrekt angewandt
   - Reproduzierbar dokumentiert

2. **Negative Ergebnisse sind wertvoll**
   - Zeigt: Perplexity allein funktioniert NICHT
   - Wichtig fÃ¼r die Forschungscommunity!
   - "Null results" sind wissenschaftlich legitim
   - Verhindert, dass andere denselben Fehler machen

3. **Interessante Insights**
   - Model Gap Problem erkannt
   - Bias durch standardisierte Texte gefunden
   - Umkehrung der Hypothese (AI hÃ¶her!) ist Ã¼berraschend
   - Klare Richtung fÃ¼r Future Work

4. **Passt perfekt fÃ¼r Assignment**
   - 3-4 Seiten IEEE Format âœ…
   - 3 Experimente wie gefordert âœ…
   - Statistisch fundiert âœ…
   - Reproduzierbar âœ…

5. **Ehrliche Wissenschaft**
   - Keine geschÃ¶nten Ergebnisse
   - Limitationen klar benannt
   - Transparente Methodik
   - Zeigt wissenschaftliche Reife

---

## ğŸ“š EMPFOHLENE QUELLEN FÃœR EUER PAPER

**Must-Have (mindestens 3-4):**

1. **DetectGPT** (State-of-the-art AI Detection)
   - Mitchell, E., Lee, Y., Khazatsky, A., Manning, C. D., & Finn, C. (2023). 
     DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. 
     *ICML 2023*.

2. **GPT-2** (Euer Perplexity-Modell)
   - Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). 
     Language Models are Unsupervised Multitask Learners. 
     *OpenAI Blog*.

3. **Perplexity Definition**
   - Brown, P. F., Della Pietra, V. J., Mercer, R. L., Della Pietra, S. A., & Lai, J. C. (1992). 
     An estimate of an upper bound for the entropy of English. 
     *Computational Linguistics*, 18(1), 31-40.

4. **AI Text Detection Survey**
   - Jawahar, G., Abdul-Mageed, M., & Lakshmanan, V. S. (2020). 
     Automatic detection of machine generated text: A critical survey. 
     *COLING 2020*.

**Nice-to-Have:**

5. **Burstiness & Perplexity**
   - Gehrmann, S., Strobelt, H., & Rush, A. M. (2019). 
     GLTR: Statistical Detection and Visualization of Generated Text. 
     *ACL 2019*.

6. **Cross-Model Detection Challenges**
   - Uchendu, A., Le, T., Shu, K., & Lee, D. (2020). 
     Authorship Attribution for Neural Text Generation. 
     *EMNLP 2020*.

---

## âš ï¸ WICHTIG - BITTE VOR PAPER-ABGABE MACHEN:

### 1. Notebook nochmal ausfÃ¼hren
**Warum?** Deine `experiment1_statistics.json` ist unvollstÃ¤ndig (endet bei `"is_significant":`).

**Schritte:**
1. Kernel neu starten (Kernel â†’ Restart Kernel)
2. Alle Zellen von oben nach unten ausfÃ¼hren
3. PrÃ¼fe dass alle JSON-Dateien vollstÃ¤ndig sind

### 2. Plots prÃ¼fen
- âœ… Ã–ffne `figures/experiment1_boxplot.png`
- âœ… Ã–ffne `figures/experiment2_roc_curve.png`
- Sind die Plots klar lesbar?
- Sind Achsenbeschriftungen korrekt?

### 3. Ergebnisse validieren
```bash
# PrÃ¼fe ob alle Dateien da sind:
ls -lh results/
ls -lh figures/
ls -lh data/combined_data.csv
```

---

## ğŸ“ PAPER-STRUKTUR (IEEE, 3-4 Seiten)

```
1. ABSTRACT (150 WÃ¶rter)
   - Motivation
   - Methode (GPT-2, 60 Texte)
   - Hauptergebnis (AI hÃ¶her, p>0.05, AUC=0.42)
   - Schlussfolgerung (Perplexity allein unzureichend)

2. INTRODUCTION (0.5 Seite)
   - Problem: AI-Text Detection wichtig
   - Perplexity als Metrik
   - Hypothese: AI niedriger
   - Forschungsfrage

3. METHOD (0.75-1 Seite)
   - Data Collection (30 Human Paper3, 30 AI ChatGPT)
   - Perplexity Calculation (GPT-2)
   - Experiments:
     * Exp 1: t-Test
     * Exp 2: ROC/AUC
     * Exp 3: Error Analysis

4. RESULTS (1-1.25 Seiten)
   - Table 1: Deskriptive Statistik
   - Table 2: t-Test (p=0.389, nicht signifikant)
   - Figure 1: Boxplot
   - Table 3: Classification (AUC=0.42)
   - Figure 2: ROC-Kurve
   - Error Analysis: 27 False Negatives

5. DISCUSSION (0.5-0.75 Seite)
   - Hypothese widerlegt â†’ AI hÃ¶her
   - Model Gap (GPT-2 vs ChatGPT)
   - Standardized text problem
   - Limitationen
   - Future Work

6. CONCLUSION (0.25 Seite)
   - Perplexity insufficient
   - Need multi-feature approaches
   - Importance of negative results

7. REFERENCES (min. 4)
```

---

## ğŸ’ª DU SCHAFFST DAS!

**Deine Arbeit bis jetzt:**
- âœ… Daten gesammelt (60 Texte)
- âœ… Code geschrieben (komplettes Notebook)
- âœ… Experimente durchgefÃ¼hrt
- âœ… Ergebnisse analysiert
- âœ… Wissenschaftlich ehrlich

**Noch zu tun:**
- ğŸ“ Paper schreiben (3-4 Seiten)
- ğŸ” Ergebnisse diskutieren
- ğŸ“š Referenzen einfÃ¼gen
- âœ… Abgeben!

**Zeit**: ~3-4 Tage fÃ¼r Paper-Schreiben (machbar!)

---

**Viel Erfolg! Du hast wissenschaftlich solide Arbeit geleistet! ğŸ“ğŸš€**
